{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "      <th>turns</th>\n",
       "      <th>user_id</th>\n",
       "      <th>wizard_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e2c0fc6c-2134-4891-8353-ef16d8412c9a</td>\n",
       "      <td>{'userSurveyRating': 4.0, 'wizardSurveyTaskSuc...</td>\n",
       "      <td>[{'text': 'I'd like to book a trip to Atlantis...</td>\n",
       "      <td>U22HTHYNP</td>\n",
       "      <td>U21DKG18C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4a3bfa39-2c22-42c8-8694-32b4e34415e9</td>\n",
       "      <td>{'userSurveyRating': 3.0, 'wizardSurveyTaskSuc...</td>\n",
       "      <td>[{'text': 'Hello, I am looking to book a vacat...</td>\n",
       "      <td>U21E41CQP</td>\n",
       "      <td>U21DMV0KA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6e67ed28-e94c-4fab-96b6-68569a92682f</td>\n",
       "      <td>{'userSurveyRating': 2.0, 'wizardSurveyTaskSuc...</td>\n",
       "      <td>[{'text': 'Hello there i am looking to go on a...</td>\n",
       "      <td>U21RP4FCY</td>\n",
       "      <td>U21E0179B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5ae76e50-5b48-4166-9f6d-67aaabd7bcaa</td>\n",
       "      <td>{'userSurveyRating': 5.0, 'wizardSurveyTaskSuc...</td>\n",
       "      <td>[{'text': 'Hi I'd like to go to Caprica from B...</td>\n",
       "      <td>U22HTHYNP</td>\n",
       "      <td>U21DKG18C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24603086-bb53-431e-a0d8-1dcc63518ba9</td>\n",
       "      <td>{'userSurveyRating': 5.0, 'wizardSurveyTaskSuc...</td>\n",
       "      <td>[{'text': 'Hello, I am looking to book a trip ...</td>\n",
       "      <td>U21E41CQP</td>\n",
       "      <td>U21DMV0KA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  e2c0fc6c-2134-4891-8353-ef16d8412c9a   \n",
       "1  4a3bfa39-2c22-42c8-8694-32b4e34415e9   \n",
       "2  6e67ed28-e94c-4fab-96b6-68569a92682f   \n",
       "3  5ae76e50-5b48-4166-9f6d-67aaabd7bcaa   \n",
       "4  24603086-bb53-431e-a0d8-1dcc63518ba9   \n",
       "\n",
       "                                              labels  \\\n",
       "0  {'userSurveyRating': 4.0, 'wizardSurveyTaskSuc...   \n",
       "1  {'userSurveyRating': 3.0, 'wizardSurveyTaskSuc...   \n",
       "2  {'userSurveyRating': 2.0, 'wizardSurveyTaskSuc...   \n",
       "3  {'userSurveyRating': 5.0, 'wizardSurveyTaskSuc...   \n",
       "4  {'userSurveyRating': 5.0, 'wizardSurveyTaskSuc...   \n",
       "\n",
       "                                               turns    user_id  wizard_id  \n",
       "0  [{'text': 'I'd like to book a trip to Atlantis...  U22HTHYNP  U21DKG18C  \n",
       "1  [{'text': 'Hello, I am looking to book a vacat...  U21E41CQP  U21DMV0KA  \n",
       "2  [{'text': 'Hello there i am looking to go on a...  U21RP4FCY  U21E0179B  \n",
       "3  [{'text': 'Hi I'd like to go to Caprica from B...  U22HTHYNP  U21DKG18C  \n",
       "4  [{'text': 'Hello, I am looking to book a trip ...  U21E41CQP  U21DMV0KA  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "patients_df = pd.read_json('frames.json')\n",
    "patients_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.DataFrame(columns=['text','intent','dst','or','dep','ret','bud'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition model\n",
    "\n",
    "the following entities has to be recognized:\n",
    "- destination\n",
    "- origin\n",
    "- budget\n",
    "- departure date\n",
    "- return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(patients_df.shape[0]):\n",
    "    dst=''\n",
    "    orr=''\n",
    "    strt=''\n",
    "    fin=''\n",
    "    bud=''\n",
    "    intent=''\n",
    "    \n",
    "    try:\n",
    "        b=patients_df.turns[i][0]['labels']['acts'][1]['args']\n",
    "    except:\n",
    "        b=[]\n",
    "    try:\n",
    "        intent=patients_df.turns[i][0]['labels']['acts'][0]['name']\n",
    "    except:\n",
    "        intent=''\n",
    "    for y in b:\n",
    "       \n",
    "        if y['key']=='dst_city':\n",
    "            des= y['val']\n",
    "        if y['key']=='or_city':\n",
    "            orr= y['val']\n",
    "        if y['key']=='str_date':\n",
    "            strt= y['val']\n",
    "        if y['key']=='end_date':\n",
    "            fin= y['val']\n",
    "        if y['key']=='budget':\n",
    "            bud= y['val']\n",
    "    data = data.append({'text':patients_df.turns[i][0]['text'],'intent':intent,\n",
    "                       'dst': des,\n",
    "                       'bud':bud,\n",
    "                       'or':orr,\n",
    "                       'dep':strt,\n",
    "                        'ret':fin }, ignore_index=True)\n",
    "    data.astype({'bud': 'object'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparing the data \n",
    "- replace 2016 year by 2020/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data['dep'].iloc[:600]=data['dep'].iloc[:600].map(lambda x:str(x).replace('2016','2020'))\n",
    "data['text'].iloc[:600]=data['text'].iloc[:600].map(lambda x:str(x).replace('2016','2020'))\n",
    "data['ret'].iloc[:600]=data['ret'].iloc[:600].map(lambda x:str(x).replace('2016','2020'))\n",
    "data['dep'].iloc[600:]=data['dep'].iloc[600:].map(lambda x:str(x).replace('2016','2021'))\n",
    "data['text'].iloc[600:]=data['text'].iloc[600:].map(lambda x:str(x).replace('2016','2021'))\n",
    "data['ret'].iloc[600:]=data['ret'].iloc[600:].map(lambda x:str(x).replace('2016','2021'))\n",
    "data=data.replace(\"\",np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "      <th>dst</th>\n",
       "      <th>or</th>\n",
       "      <th>dep</th>\n",
       "      <th>ret</th>\n",
       "      <th>bud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1369</td>\n",
       "      <td>1366</td>\n",
       "      <td>1369</td>\n",
       "      <td>585</td>\n",
       "      <td>272</td>\n",
       "      <td>151</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1329</td>\n",
       "      <td>2</td>\n",
       "      <td>219</td>\n",
       "      <td>221</td>\n",
       "      <td>157</td>\n",
       "      <td>118</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>hi</td>\n",
       "      <td>inform</td>\n",
       "      <td>-1</td>\n",
       "      <td>Kabul</td>\n",
       "      <td>August 27th</td>\n",
       "      <td>24th</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>10</td>\n",
       "      <td>1022</td>\n",
       "      <td>50</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text  intent   dst     or          dep   ret  bud\n",
       "count   1369    1366  1369    585          272   151  170\n",
       "unique  1329       2   219    221          157   118   94\n",
       "top       hi  inform    -1  Kabul  August 27th  24th   -1\n",
       "freq      10    1022    50     14           10     3   15"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         0\n",
       "intent       3\n",
       "dst          0\n",
       "or         784\n",
       "dep       1097\n",
       "ret       1218\n",
       "bud       1199\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].map(lambda x: len(x.split())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "      <th>dst</th>\n",
       "      <th>or</th>\n",
       "      <th>dep</th>\n",
       "      <th>ret</th>\n",
       "      <th>bud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'd like to book a trip to Atlantis from Capri...</td>\n",
       "      <td>inform</td>\n",
       "      <td>Atlantis</td>\n",
       "      <td>Caprica</td>\n",
       "      <td>Saturday, August 13, 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello, I am looking to book a vacation from Go...</td>\n",
       "      <td>inform</td>\n",
       "      <td>Mos Eisley</td>\n",
       "      <td>Gotham City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello there i am looking to go on a vacation w...</td>\n",
       "      <td>inform</td>\n",
       "      <td>Gotham City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi I'd like to go to Caprica from Busan, betwe...</td>\n",
       "      <td>inform</td>\n",
       "      <td>Caprica</td>\n",
       "      <td>Busan</td>\n",
       "      <td>Sunday August 21, 2020</td>\n",
       "      <td>Wednesday August 31, 2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello, I am looking to book a trip for 2 adult...</td>\n",
       "      <td>inform</td>\n",
       "      <td>Denver</td>\n",
       "      <td>Kochi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$21,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hey, i Want to go to St. Louis on the 17th of ...</td>\n",
       "      <td>inform</td>\n",
       "      <td>St. Louis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17th of August</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I'm looking for a trip to Gotham City leaving ...</td>\n",
       "      <td>inform</td>\n",
       "      <td>Gotham City</td>\n",
       "      <td>Kakariko Village</td>\n",
       "      <td>Saturday, August 13, 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$2400 USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hello, I would like to book a 2-week trip leav...</td>\n",
       "      <td>greeting</td>\n",
       "      <td>Gotham City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hello, I am planning to book a trip to pittsborgh</td>\n",
       "      <td>inform</td>\n",
       "      <td>pittsborgh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hi, I need to go to Mos Eisley for a wedding, ...</td>\n",
       "      <td>inform</td>\n",
       "      <td>Mos Eisley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saturday, August 13, 2020</td>\n",
       "      <td>Tuesday, August 16, 2020</td>\n",
       "      <td>$3700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    intent          dst  \\\n",
       "0  I'd like to book a trip to Atlantis from Capri...    inform     Atlantis   \n",
       "1  Hello, I am looking to book a vacation from Go...    inform   Mos Eisley   \n",
       "2  Hello there i am looking to go on a vacation w...    inform  Gotham City   \n",
       "3  Hi I'd like to go to Caprica from Busan, betwe...    inform      Caprica   \n",
       "4  Hello, I am looking to book a trip for 2 adult...    inform       Denver   \n",
       "5  Hey, i Want to go to St. Louis on the 17th of ...    inform    St. Louis   \n",
       "6  I'm looking for a trip to Gotham City leaving ...    inform  Gotham City   \n",
       "7  Hello, I would like to book a 2-week trip leav...  greeting  Gotham City   \n",
       "8  Hello, I am planning to book a trip to pittsborgh    inform   pittsborgh   \n",
       "9  Hi, I need to go to Mos Eisley for a wedding, ...    inform   Mos Eisley   \n",
       "\n",
       "                 or                        dep                        ret  \\\n",
       "0           Caprica  Saturday, August 13, 2020                        NaN   \n",
       "1       Gotham City                        NaN                        NaN   \n",
       "2               NaN                        NaN                        NaN   \n",
       "3             Busan     Sunday August 21, 2020  Wednesday August 31, 2020   \n",
       "4             Kochi                        NaN                        NaN   \n",
       "5               NaN             17th of August                        NaN   \n",
       "6  Kakariko Village  Saturday, August 13, 2020                        NaN   \n",
       "7               NaN                        NaN                        NaN   \n",
       "8               NaN                        NaN                        NaN   \n",
       "9               NaN  Saturday, August 13, 2020   Tuesday, August 16, 2020   \n",
       "\n",
       "         bud  \n",
       "0       1700  \n",
       "1       2100  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4    $21,300  \n",
       "5        NaN  \n",
       "6  $2400 USD  \n",
       "7        NaN  \n",
       "8        NaN  \n",
       "9      $3700  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "words=[]\n",
    "tokens=[]\n",
    "for index, row in data.iterrows():\n",
    "    if row['intent']==\"inform\":\n",
    "        to=[]\n",
    "        text=row['text'].lower().translate(str.maketrans('', '', string.punctuation))\n",
    "        li= text.split()\n",
    "        \n",
    "        for w in li:\n",
    "            if w in map(lambda x:x.lower(),str(row['dst']).translate(str.maketrans('', '', string.punctuation)).split()):\n",
    "                to.append(1)\n",
    "            elif w in map(lambda x:x.lower(),str(row['or']).translate(str.maketrans('', '', string.punctuation)).split()):\n",
    "                to.append(2)\n",
    "            elif w in map(lambda x:x.lower(), str(row['dep']).translate(str.maketrans('', '', string.punctuation)).split()):\n",
    "                to.append(3)\n",
    "            elif w in map(lambda x:x.lower(),str(row['ret']).translate(str.maketrans('', '', string.punctuation)).split()):\n",
    "                to.append(4)\n",
    "            elif w==str(row['bud']).translate(str.maketrans('', '', string.punctuation)):\n",
    "                to.append(5)\n",
    "            else:\n",
    "                to.append(0)\n",
    "        words.append(li)\n",
    "        tokens.append(to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "words1=[item for sublist in words for item in sublist]\n",
    "words1= list(map(lambda x:x.lower(),str(words1).translate(str.maketrans('', '', string.punctuation)).split()))\n",
    "words1.append(\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check length\n",
    "pairs=[]\n",
    "for i in range(len (words)):\n",
    "    if len(words[i])!=len(tokens[i]):\n",
    "        print(str(len(words[i]))+str(len(tokens[i])))\n",
    "    else:\n",
    "        sentense=[]\n",
    "        for y in range(len(words[i])):\n",
    "            item=(words[i][y],tokens[i][y])\n",
    "            sentense.append(item)\n",
    "    pairs.append(sentense)\n",
    "                    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep=[]\n",
    "for i in words:\n",
    "    arr=[]\n",
    "    for y in i:\n",
    "        arr.append(words1.index(y))\n",
    "    if len(arr)<74:\n",
    "        arr.extend([len(words1)-1]*(74-len(arr)))\n",
    "    prep.append(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tokens:\n",
    "    \n",
    "        if len(i)<74:\n",
    "            \n",
    "            i.extend([0]*(74-len(i)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 74)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 74, 1000)          18203000  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 74, 400)           1921600   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 74, 100)           200400    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 74, 6)             606       \n",
      "=================================================================\n",
      "Total params: 20,325,606\n",
      "Trainable params: 20,325,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding,Bidirectional,TimeDistributed\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "input = Input(shape=(74,))\n",
    "\n",
    "    # Add Embedding layer\n",
    "    \n",
    "x=Embedding(len(words1)+1, 1000)(input)\n",
    "\n",
    "    # Add bidirectional LSTM\n",
    "x=Bidirectional(LSTM(units=200, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat')(x)\n",
    "\n",
    "    # Add LSTM\n",
    "x=LSTM(units=100, return_sequences=True, dropout=0.5, recurrent_dropout=0.5)(x)\n",
    "\n",
    "z=Dense(6, activation=\"softmax\")\n",
    "    # Add timeDistributed Layer\n",
    "y=TimeDistributed(z)(x)\n",
    "\n",
    "model = Model(inputs=input,outputs=y)\n",
    "model.summary()\n",
    "\n",
    "    # Compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lesh3\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 919 samples, validate on 103 samples\n",
      "Epoch 1/50\n",
      "919/919 [==============================] - 30s 33ms/step - loss: 0.3151 - accuracy: 0.9376 - val_loss: 0.1146 - val_accuracy: 0.9759\n",
      "Epoch 2/50\n",
      "919/919 [==============================] - 29s 32ms/step - loss: 0.1350 - accuracy: 0.9693 - val_loss: 0.0973 - val_accuracy: 0.9759\n",
      "Epoch 3/50\n",
      "919/919 [==============================] - 29s 32ms/step - loss: 0.1121 - accuracy: 0.9693 - val_loss: 0.0798 - val_accuracy: 0.9761\n",
      "Epoch 4/50\n",
      "919/919 [==============================] - 29s 32ms/step - loss: 0.0871 - accuracy: 0.9704 - val_loss: 0.0603 - val_accuracy: 0.9786\n",
      "Epoch 5/50\n",
      "919/919 [==============================] - 29s 32ms/step - loss: 0.0672 - accuracy: 0.9753 - val_loss: 0.0489 - val_accuracy: 0.9841\n",
      "Epoch 6/50\n",
      "919/919 [==============================] - 28s 31ms/step - loss: 0.0577 - accuracy: 0.9794 - val_loss: 0.0418 - val_accuracy: 0.9874\n",
      "Epoch 7/50\n",
      "919/919 [==============================] - 28s 30ms/step - loss: 0.0496 - accuracy: 0.9827 - val_loss: 0.0352 - val_accuracy: 0.9892\n",
      "Epoch 8/50\n",
      "919/919 [==============================] - 32s 35ms/step - loss: 0.0384 - accuracy: 0.9870 - val_loss: 0.0300 - val_accuracy: 0.9908\n",
      "Epoch 9/50\n",
      "919/919 [==============================] - 33s 36ms/step - loss: 0.0322 - accuracy: 0.9888 - val_loss: 0.0270 - val_accuracy: 0.9916\n",
      "Epoch 10/50\n",
      "919/919 [==============================] - 33s 36ms/step - loss: 0.0283 - accuracy: 0.9903 - val_loss: 0.0255 - val_accuracy: 0.9921\n",
      "Epoch 11/50\n",
      "919/919 [==============================] - 29s 32ms/step - loss: 0.0251 - accuracy: 0.9913 - val_loss: 0.0248 - val_accuracy: 0.9930\n",
      "Epoch 12/50\n",
      "919/919 [==============================] - 29s 32ms/step - loss: 0.0224 - accuracy: 0.9923 - val_loss: 0.0242 - val_accuracy: 0.9936\n",
      "Epoch 13/50\n",
      "919/919 [==============================] - 29s 32ms/step - loss: 0.0201 - accuracy: 0.9932 - val_loss: 0.0246 - val_accuracy: 0.9934\n",
      "Epoch 14/50\n",
      "919/919 [==============================] - 29s 31ms/step - loss: 0.0181 - accuracy: 0.9938 - val_loss: 0.0257 - val_accuracy: 0.9928\n",
      "Epoch 15/50\n",
      "919/919 [==============================] - 29s 31ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0244 - val_accuracy: 0.9937\n",
      "Epoch 16/50\n",
      "919/919 [==============================] - 29s 32ms/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.0245 - val_accuracy: 0.9933\n",
      "Epoch 17/50\n",
      "919/919 [==============================] - 30s 33ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.0251 - val_accuracy: 0.9936\n",
      "Epoch 18/50\n",
      "919/919 [==============================] - 30s 32ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.0266 - val_accuracy: 0.9932\n",
      "Epoch 19/50\n",
      "919/919 [==============================] - 29s 32ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.0276 - val_accuracy: 0.9933\n",
      "Epoch 20/50\n",
      "919/919 [==============================] - 30s 32ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0291 - val_accuracy: 0.9923\n",
      "Epoch 21/50\n",
      "919/919 [==============================] - 30s 33ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.0281 - val_accuracy: 0.9934\n",
      "Epoch 22/50\n",
      "919/919 [==============================] - 29s 32ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.0339 - val_accuracy: 0.9911\n",
      "Epoch 23/50\n",
      "919/919 [==============================] - 30s 32ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0324 - val_accuracy: 0.9913\n",
      "Epoch 24/50\n",
      "919/919 [==============================] - 31s 34ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.0414 - val_accuracy: 0.9907\n",
      "Epoch 25/50\n",
      "919/919 [==============================] - 30s 32ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0373 - val_accuracy: 0.9913\n",
      "Epoch 26/50\n",
      "919/919 [==============================] - 30s 32ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.0397 - val_accuracy: 0.9908\n",
      "Epoch 27/50\n",
      "919/919 [==============================] - 30s 32ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0416 - val_accuracy: 0.9912\n",
      "Epoch 28/50\n",
      "919/919 [==============================] - 30s 32ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0452 - val_accuracy: 0.9907\n",
      "Epoch 29/50\n",
      "919/919 [==============================] - 30s 33ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0419 - val_accuracy: 0.9915\n",
      "Epoch 30/50\n",
      "919/919 [==============================] - 31s 33ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0505 - val_accuracy: 0.9909\n",
      "Epoch 31/50\n",
      "919/919 [==============================] - 31s 34ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0397 - val_accuracy: 0.9923\n",
      "Epoch 32/50\n",
      "919/919 [==============================] - 30s 32ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0478 - val_accuracy: 0.9909\n",
      "Epoch 33/50\n",
      "919/919 [==============================] - 30s 33ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0509 - val_accuracy: 0.9898\n",
      "Epoch 34/50\n",
      "919/919 [==============================] - 30s 32ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0515 - val_accuracy: 0.9903\n",
      "Epoch 35/50\n",
      "919/919 [==============================] - 30s 32ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0500 - val_accuracy: 0.9906\n",
      "Epoch 36/50\n",
      "919/919 [==============================] - 30s 32ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0491 - val_accuracy: 0.9913\n",
      "Epoch 37/50\n",
      "919/919 [==============================] - 30s 33ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0489 - val_accuracy: 0.9908\n",
      "Epoch 38/50\n",
      "919/919 [==============================] - 32s 35ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0527 - val_accuracy: 0.9906\n",
      "Epoch 39/50\n",
      "919/919 [==============================] - 30s 32ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0551 - val_accuracy: 0.9892\n",
      "Epoch 40/50\n",
      "919/919 [==============================] - 32s 34ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.0539 - val_accuracy: 0.9907\n",
      "Epoch 41/50\n",
      "919/919 [==============================] - 30s 33ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0613 - val_accuracy: 0.9894\n",
      "Epoch 42/50\n",
      "919/919 [==============================] - 31s 33ms/step - loss: 0.0106 - accuracy: 0.9971 - val_loss: 0.0584 - val_accuracy: 0.9908\n",
      "Epoch 43/50\n",
      "919/919 [==============================] - 31s 33ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0549 - val_accuracy: 0.9896\n",
      "Epoch 44/50\n",
      "919/919 [==============================] - 32s 35ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0503 - val_accuracy: 0.9907\n",
      "Epoch 45/50\n",
      "919/919 [==============================] - 33s 36ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0583 - val_accuracy: 0.9898\n",
      "Epoch 46/50\n",
      "919/919 [==============================] - 32s 35ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0550 - val_accuracy: 0.9907\n",
      "Epoch 47/50\n",
      "919/919 [==============================] - 32s 35ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0589 - val_accuracy: 0.9902\n",
      "Epoch 48/50\n",
      "919/919 [==============================] - 32s 35ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0566 - val_accuracy: 0.9908\n",
      "Epoch 49/50\n",
      "919/919 [==============================] - 32s 35ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0562 - val_accuracy: 0.9911\n",
      "Epoch 50/50\n",
      "919/919 [==============================] - 32s 35ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0562 - val_accuracy: 0.9917\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "history = model.fit(np.array(prep), np.expand_dims(np.array(tokens), axis=2),\n",
    "                    \n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,workers=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"modelChatNer.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"modelChatNer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict.txt', 'w') as f:\n",
    "    for item in words1:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"dict.txt\", \"r\")\n",
    "lines = text_file.read().split('\\n')\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial= \"travel to new york from miami the first week of august 2020 and back in september 2020\".lower().translate(str.maketrans('', '', string.punctuation)).split()\n",
    "trial.extend([\"none\"]*(74-len(trial)))\n",
    "\n",
    "ready=[]\n",
    "for i in trial:\n",
    "        ready.append(words1.index(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'new': [1, 0.865208]}, {'york': [1, 0.997886]}, {'miami': [2, 0.9922672]}, {'first': [3, 0.9869876]}, {'week': [3, 0.48395985]}, {'of': [4, 0.9000157]}, {'august': [3, 0.9650315]}, {'2020': [3, 0.9926489]}, {'september': [4, 0.9807802]}, {'2020': [3, 0.98176575]}]\n"
     ]
    }
   ],
   "source": [
    "f=model.predict(np.array([ready]))\n",
    "ff=np.argmax(f, axis=2)\n",
    "arr=[]\n",
    "for i in range (len(trial)):\n",
    "    if ff[0][i]!=0:\n",
    "        arr.append({trial[i]:[ff[0][i], f[0][i][ff[0][i]]]})\n",
    "        \n",
    "       \n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textual analysis ( intent recognition ) model\n",
    "-adding extra data not releated to bookings to have equal binary target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets= pd.read_csv('twcs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count             2811774\n",
       "unique            2782618\n",
       "top       @AirAsiaSupport\n",
       "freq                  287\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['text'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_list=['@','//']\n",
    "res = [ele for ele in tweets['text'] if all(ch not in ele for ch in char_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "import re\n",
    "res1=[]\n",
    "for i in res:\n",
    "    try:\n",
    "        if  i.encode(encoding='utf-8').decode('ascii'):\n",
    "            res1.append(i)\n",
    "    except UnicodeDecodeError:\n",
    "        var=''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "add=pd.DataFrame({'text':res1,'intent':0}).iloc[10000:11000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>Really waiting at this door for ups to pull up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>I only fly virgin airlines bc they cabins turn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>McDonald's fountain coke is the best</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>do i dare leave my bed rn to get a mcdouble</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>Someone bring me a strawberry cream pie from M...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  intent\n",
       "10000     Really waiting at this door for ups to pull up       0\n",
       "10001  I only fly virgin airlines bc they cabins turn...       0\n",
       "10002               McDonald's fountain coke is the best       0\n",
       "10003        do i dare leave my bed rn to get a mcdouble       0\n",
       "10004  Someone bring me a strawberry cream pie from M...       0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "full=add.append( pd.DataFrame({'text':data['text'],'intent':data['intent']}),ignore_index = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['intent']=full['intent'].apply(lambda x:1 if x==\"inform\" else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>yo fam want to take my girl down to Punta Cana</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>I want to go to Paris from Maceio with 6200$.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>Hi! I'm looking to go from Essen to San Juan b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>Hello, I'm looking to go from Essen to Mannheim</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>hi. I want to go to Tofino from Burlington. pl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>Hi there</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>hello</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>Hey</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>Hi there, I'm planning a family vacation and w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>I dream of a better life and I want to go to S...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  intent\n",
       "1345     yo fam want to take my girl down to Punta Cana       1\n",
       "1346      I want to go to Paris from Maceio with 6200$.       1\n",
       "1347  Hi! I'm looking to go from Essen to San Juan b...       1\n",
       "1348    Hello, I'm looking to go from Essen to Mannheim       1\n",
       "1349  hi. I want to go to Tofino from Burlington. pl...       0\n",
       "1350                                           Hi there       0\n",
       "1351                                              hello       0\n",
       "1352                                                Hey       0\n",
       "1353  Hi there, I'm planning a family vacation and w...       1\n",
       "1354  I dream of a better life and I want to go to S...       1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.iloc[1345:].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y=train_test_split(full['text'], full['intent'], test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# define Tokenizer with Vocab Size\n",
    "tokenizer = Tokenizer(num_words=15000)\n",
    "tokenizer.fit_on_texts(full['text'])\n",
    " \n",
    "X = tokenizer.texts_to_sequences(full['text'])\n",
    "X = pad_sequences(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y=train_test_split(X, full['intent'], test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open('tokenizer1Chat.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_28 (InputLayer)        (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "embedding_26 (Embedding)     (None, 75, 300)           4500300   \n",
      "_________________________________________________________________\n",
      "lstm_40 (LSTM)               (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,610,637\n",
      "Trainable params: 4,610,637\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "input = Input(shape=(75,))\n",
    "x = Embedding(15000 + 1, 300)(input)\n",
    "y =LSTM(64)(x)\n",
    "y= Dense(256,name='FC1')(y)\n",
    "y= Activation('relu')(y)\n",
    "y= Dropout(0.5)(y)\n",
    "z= Dense(1,name='out_layer')(y)\n",
    "z= Activation('sigmoid')(z)\n",
    "model = Model(inputs=input,outputs=z)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lesh3\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1918 samples, validate on 214 samples\n",
      "Epoch 1/50\n",
      "1918/1918 [==============================] - 15s 8ms/step - loss: 0.0193 - accuracy: 0.9937 - val_loss: 1.2298 - val_accuracy: 0.8271\n",
      "Epoch 2/50\n",
      "1918/1918 [==============================] - 16s 8ms/step - loss: 0.0187 - accuracy: 0.9953 - val_loss: 1.1687 - val_accuracy: 0.8271\n",
      "Epoch 3/50\n",
      "1918/1918 [==============================] - 16s 8ms/step - loss: 6.8786e-04 - accuracy: 1.0000 - val_loss: 1.2227 - val_accuracy: 0.8224\n",
      "Epoch 4/50\n",
      "1918/1918 [==============================] - 15s 8ms/step - loss: 2.5350e-04 - accuracy: 1.0000 - val_loss: 1.2351 - val_accuracy: 0.8318\n",
      "Epoch 5/50\n",
      "1918/1918 [==============================] - 15s 8ms/step - loss: 1.6100e-04 - accuracy: 1.0000 - val_loss: 1.2491 - val_accuracy: 0.8318\n",
      "Epoch 6/50\n",
      "1918/1918 [==============================] - 15s 8ms/step - loss: 1.4550e-04 - accuracy: 1.0000 - val_loss: 1.2515 - val_accuracy: 0.8411\n",
      "Epoch 7/50\n",
      "1918/1918 [==============================] - 15s 8ms/step - loss: 1.2075e-04 - accuracy: 1.0000 - val_loss: 1.2643 - val_accuracy: 0.8411\n",
      "Epoch 8/50\n",
      "1918/1918 [==============================] - 15s 8ms/step - loss: 8.7861e-05 - accuracy: 1.0000 - val_loss: 1.2750 - val_accuracy: 0.8364\n",
      "Epoch 9/50\n",
      "1918/1918 [==============================] - 14s 7ms/step - loss: 9.0023e-05 - accuracy: 1.0000 - val_loss: 1.2914 - val_accuracy: 0.8411\n",
      "Epoch 10/50\n",
      "1918/1918 [==============================] - 14s 7ms/step - loss: 6.1100e-05 - accuracy: 1.0000 - val_loss: 1.3088 - val_accuracy: 0.8411\n",
      "Epoch 11/50\n",
      "1918/1918 [==============================] - 15s 8ms/step - loss: 5.5309e-05 - accuracy: 1.0000 - val_loss: 1.3277 - val_accuracy: 0.8411\n",
      "Epoch 12/50\n",
      "1918/1918 [==============================] - 17s 9ms/step - loss: 3.8677e-05 - accuracy: 1.0000 - val_loss: 1.3475 - val_accuracy: 0.8411\n",
      "Epoch 13/50\n",
      "1918/1918 [==============================] - 16s 9ms/step - loss: 4.1689e-05 - accuracy: 1.0000 - val_loss: 1.3563 - val_accuracy: 0.8411\n",
      "Epoch 14/50\n",
      "1918/1918 [==============================] - 16s 8ms/step - loss: 3.3707e-05 - accuracy: 1.0000 - val_loss: 1.3710 - val_accuracy: 0.8364\n",
      "Epoch 15/50\n",
      "1918/1918 [==============================] - 15s 8ms/step - loss: 2.7946e-05 - accuracy: 1.0000 - val_loss: 1.3831 - val_accuracy: 0.8364\n",
      "Epoch 16/50\n",
      "1918/1918 [==============================] - 17s 9ms/step - loss: 3.6082e-05 - accuracy: 1.0000 - val_loss: 1.3900 - val_accuracy: 0.8411\n",
      "Epoch 17/50\n",
      "1918/1918 [==============================] - 17s 9ms/step - loss: 2.1406e-05 - accuracy: 1.0000 - val_loss: 1.4045 - val_accuracy: 0.8364\n",
      "Epoch 18/50\n",
      "1918/1918 [==============================] - 17s 9ms/step - loss: 2.3317e-05 - accuracy: 1.0000 - val_loss: 1.4167 - val_accuracy: 0.8364\n",
      "Epoch 19/50\n",
      "1918/1918 [==============================] - 17s 9ms/step - loss: 1.7941e-05 - accuracy: 1.0000 - val_loss: 1.4337 - val_accuracy: 0.8364\n",
      "Epoch 20/50\n",
      "1918/1918 [==============================] - 16s 9ms/step - loss: 1.7933e-05 - accuracy: 1.0000 - val_loss: 1.4451 - val_accuracy: 0.8364\n",
      "Epoch 21/50\n",
      "1918/1918 [==============================] - 16s 9ms/step - loss: 2.0124e-05 - accuracy: 1.0000 - val_loss: 1.4558 - val_accuracy: 0.8364\n",
      "Epoch 22/50\n",
      "1918/1918 [==============================] - 17s 9ms/step - loss: 2.2442e-05 - accuracy: 1.0000 - val_loss: 1.4643 - val_accuracy: 0.8364\n",
      "Epoch 23/50\n",
      "1918/1918 [==============================] - 17s 9ms/step - loss: 1.8002e-05 - accuracy: 1.0000 - val_loss: 1.4783 - val_accuracy: 0.8411\n",
      "Epoch 24/50\n",
      "1918/1918 [==============================] - 16s 8ms/step - loss: 1.0658e-05 - accuracy: 1.0000 - val_loss: 1.4896 - val_accuracy: 0.8411\n",
      "Epoch 25/50\n",
      "1918/1918 [==============================] - 17s 9ms/step - loss: 8.5799e-06 - accuracy: 1.0000 - val_loss: 1.4984 - val_accuracy: 0.8411\n",
      "Epoch 26/50\n",
      "1918/1918 [==============================] - 17s 9ms/step - loss: 1.4457e-05 - accuracy: 1.0000 - val_loss: 1.5076 - val_accuracy: 0.8364\n",
      "Epoch 27/50\n",
      "1918/1918 [==============================] - 18s 9ms/step - loss: 1.1134e-05 - accuracy: 1.0000 - val_loss: 1.5184 - val_accuracy: 0.8364\n",
      "Epoch 28/50\n",
      "1918/1918 [==============================] - 17s 9ms/step - loss: 9.4000e-06 - accuracy: 1.0000 - val_loss: 1.5279 - val_accuracy: 0.8364\n",
      "Epoch 29/50\n",
      "1918/1918 [==============================] - 17s 9ms/step - loss: 1.0255e-05 - accuracy: 1.0000 - val_loss: 1.5410 - val_accuracy: 0.8364\n",
      "Epoch 30/50\n",
      "1918/1918 [==============================] - 17s 9ms/step - loss: 1.1024e-05 - accuracy: 1.0000 - val_loss: 1.5480 - val_accuracy: 0.8364\n",
      "Epoch 31/50\n",
      "1918/1918 [==============================] - 17s 9ms/step - loss: 6.0314e-06 - accuracy: 1.0000 - val_loss: 1.5543 - val_accuracy: 0.8364\n",
      "Epoch 32/50\n",
      "1918/1918 [==============================] - 16s 9ms/step - loss: 6.0707e-06 - accuracy: 1.0000 - val_loss: 1.5641 - val_accuracy: 0.8364\n",
      "Epoch 33/50\n",
      "1918/1918 [==============================] - 16s 9ms/step - loss: 5.4797e-06 - accuracy: 1.0000 - val_loss: 1.5752 - val_accuracy: 0.8364\n",
      "Epoch 34/50\n",
      "1918/1918 [==============================] - 17s 9ms/step - loss: 5.6158e-06 - accuracy: 1.0000 - val_loss: 1.5872 - val_accuracy: 0.8364\n",
      "Epoch 35/50\n",
      "1918/1918 [==============================] - 16s 9ms/step - loss: 7.5853e-06 - accuracy: 1.0000 - val_loss: 1.5925 - val_accuracy: 0.8364\n",
      "Epoch 36/50\n",
      "1918/1918 [==============================] - 16s 9ms/step - loss: 9.5634e-06 - accuracy: 1.0000 - val_loss: 1.6057 - val_accuracy: 0.8364\n",
      "Epoch 37/50\n",
      "1918/1918 [==============================] - 16s 9ms/step - loss: 5.8162e-06 - accuracy: 1.0000 - val_loss: 1.6133 - val_accuracy: 0.8364\n",
      "Epoch 38/50\n",
      "1918/1918 [==============================] - 16s 9ms/step - loss: 4.7011e-06 - accuracy: 1.0000 - val_loss: 1.6207 - val_accuracy: 0.8364\n",
      "Epoch 39/50\n",
      "1918/1918 [==============================] - 17s 9ms/step - loss: 3.6069e-06 - accuracy: 1.0000 - val_loss: 1.6275 - val_accuracy: 0.8364\n",
      "Epoch 40/50\n",
      "1918/1918 [==============================] - 17s 9ms/step - loss: 2.9323e-06 - accuracy: 1.0000 - val_loss: 1.6363 - val_accuracy: 0.8364\n",
      "Epoch 41/50\n",
      "1918/1918 [==============================] - 17s 9ms/step - loss: 5.6286e-06 - accuracy: 1.0000 - val_loss: 1.6413 - val_accuracy: 0.8364\n",
      "Epoch 42/50\n",
      "1918/1918 [==============================] - 17s 9ms/step - loss: 4.0683e-06 - accuracy: 1.0000 - val_loss: 1.6493 - val_accuracy: 0.8364\n",
      "Epoch 43/50\n",
      "1918/1918 [==============================] - 17s 9ms/step - loss: 3.2031e-06 - accuracy: 1.0000 - val_loss: 1.6566 - val_accuracy: 0.8364\n",
      "Epoch 44/50\n",
      "1918/1918 [==============================] - 17s 9ms/step - loss: 3.0524e-06 - accuracy: 1.0000 - val_loss: 1.6670 - val_accuracy: 0.8364\n",
      "Epoch 45/50\n",
      "1918/1918 [==============================] - 16s 9ms/step - loss: 2.8172e-06 - accuracy: 1.0000 - val_loss: 1.6764 - val_accuracy: 0.8364\n",
      "Epoch 46/50\n",
      "1918/1918 [==============================] - 16s 9ms/step - loss: 2.1936e-06 - accuracy: 1.0000 - val_loss: 1.6834 - val_accuracy: 0.8364\n",
      "Epoch 47/50\n",
      "1918/1918 [==============================] - 17s 9ms/step - loss: 2.5700e-06 - accuracy: 1.0000 - val_loss: 1.6911 - val_accuracy: 0.8364\n",
      "Epoch 48/50\n",
      "1918/1918 [==============================] - 16s 8ms/step - loss: 2.2838e-06 - accuracy: 1.0000 - val_loss: 1.6956 - val_accuracy: 0.8364\n",
      "Epoch 49/50\n",
      "1918/1918 [==============================] - 17s 9ms/step - loss: 3.3363e-06 - accuracy: 1.0000 - val_loss: 1.7055 - val_accuracy: 0.8364\n",
      "Epoch 50/50\n",
      "1918/1918 [==============================] - 15s 8ms/step - loss: 2.6875e-06 - accuracy: 1.0000 - val_loss: 1.7103 - val_accuracy: 0.8364\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "history = model.fit(train_x, train_y,\n",
    "                    \n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1, workers=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237/237 [==============================] - 0s 711us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3341485478204012, 0.8649789094924927]"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0004\n",
      "0.9999\n"
     ]
    }
   ],
   "source": [
    "def check(Z):\n",
    "    \n",
    "    Z = tokenizer.texts_to_sequences([Z])\n",
    "\n",
    "    Z=pad_sequences(Z, maxlen=75, dtype='int32', value=0)\n",
    "\n",
    "\n",
    "\n",
    "    f=model.predict(Z)\n",
    "    \n",
    "    print(round(f[0][0],4))\n",
    "\n",
    "check(\"Wanna get to LA for a week on thursday\")\n",
    "check(\"Call doctor I'am sick\")\n",
    "check(\"Hi, how are you?\")\n",
    "check(\"What time is it now?\")\n",
    "check(\"Travel from moscow to wien\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
